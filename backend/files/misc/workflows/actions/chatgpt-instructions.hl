
/*
 * Invokes ChatGPT with the specified [prompt], [model], [max_tokens] and [instruction].
 *
 * Will use the default API key found from configurations and send the [prompt] to ChatGPT
 * to have the [model] you supply answer your question without any context, but using the specified
 * [instruction] to modify the model's behavior. Try using for instance
 * "Answer my question as if I am 5 years old in one sentence" for instance as your [instruction]
 * to understand how it works.
 */
.arguments
   model
      type:enum
      mandatory:bool:true
      default:gpt-4-1106-preview
      values
         .:gpt-3.5-turbo
         .:gpt-3.5-turbo-16k
         .:gpt-4
         .:gpt-4-1106-preview
   max_tokens
      type:int
      mandatory:bool:true
      default:int:1500
   instruction
      type:textarea
      mandatory:bool:true
   prompt
      type:textarea
      mandatory:bool:true
.icon:chat_bubble

// Sanity checking invocation.
validators.mandatory:x:@.arguments/*/model
validators.mandatory:x:@.arguments/*/prompt
validators.mandatory:x:@.arguments/*/max_tokens

// Retrieving OpenAI API token from configuration settings.
.token
set-value:x:@.token
   strings.concat
      .:"Bearer "
      config.get:"magic:openai:key"

// Invokes OpenAI.
http.post:"https://api.openai.com/v1/chat/completions"
   convert:bool:true
   headers
      Authorization:x:@.token
      Content-Type:application/json
   payload
      model:x:@.arguments/*/model
      max_tokens:x:@.arguments/*/max_tokens
      temperature:decimal:0.3
      messages
         .
            role:system
            content:x:@.arguments/*/instruction
         .
            role:user
            content:x:@.arguments/*/prompt

// Sanity checking above invocation.
if
   not
      and
         mte:x:@http.post
            .:int:200
         lt:x:@http.post
            .:int:300
   .lambda

      // Oops, error - Logging error and returning status 500 to caller.
      lambda2hyper:x:@http.post
      log.error:Something went wrong while invoking OpenAI
         message:x:@http.post/*/content/*/error/*/message
         status:x:@http.post
         error:x:@lambda2hyper
      throw:Something went wrong while invoking OpenAI
         message:x:@http.post/*/content/*/error/*/message
         status:x:@http.post
         error:x:@lambda2hyper

// Returning result to caller.
yield
   result:x:@http.post/*/content/*/choices/0/*/message/*/content
